{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import utils\n",
    "import argparse\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data\n",
    "from torch import optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.nn import init\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import random\n",
    "import glob\n",
    "import os\n",
    "import torchvision.utils as vutils\n",
    "\n",
    "\n",
    "# argparser\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--dataroot\", type=str, default=\"../datasets\", help=\"path to folder containing datasets\")\n",
    "parser.add_argument(\"--dataset\", type=str, default=\"human2anime\", help=\"name of dataset (default: 'human2anime')\")\n",
    "parser.add_argument(\"--n-epochs\", type=int, default=200, help=\"total number of training epochs\")\n",
    "parser.add_argument(\"--decay-epoch\", type=int, default=100, help=\"epoch to start linearly decaying learning rate\")\n",
    "parser.add_argument(\"--image-size\", type=int, default=256, help='pixel-size of the image')\n",
    "parser.add_argument(\"-b\", \"--batch-size\", type=int, default=1, help=\"batch size\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"learning rate\")\n",
    "parser.add_argument(\"--out\", type=str, default=\"./output\", help=\"output path\")\n",
    "parser.add_argument(\"--cuda\", type=utils.str2bool, nargs='?', const=True, default=True,\n",
    "                    help='true/false value indicating whether to use cuda')\n",
    "parser.add_argument(\"--input_nc\", type=int, default=3, help='number of channels of input data')\n",
    "parser.add_argument(\"--output_nc\", type=int, default=3, help='number of channels of output data')\n",
    "parser.add_argument(\"--log-freq\", type=int, default=200, help='frequency of printing losses to stdout')\n",
    "parser.add_argument(\"--visdom-freq\", type=int, default=1000, help='frequency of showing training results in visdom')\n",
    "parser.add_argument(\"--save-freq\", type=int, default=1000, help=\"frequency to save images\")\n",
    "parser.add_argument(\"--visdom\", type=utils.str2bool, nargs='?', const=True, default=False,\n",
    "                    help='true/false value indicating whether to use visdom')\n",
    "parser.add_argument(\"--save-images\", type=utils.str2bool, nargs='?', const=True, default=True,\n",
    "                    help='true/false value indicating whether to save images generated during training')\n",
    "parser.add_argument(\"--verbose\", type=utils.str2bool, nargs='?', const=True, default=True,\n",
    "                    help='true/false value indicating whether to use tqdm')\n",
    "parser.add_argument(\"--log\", type=utils.str2bool, nargs='?', const=True, default=False,\n",
    "                    help='true/false value indicating whether to log losses during training if not using tqdm')\n",
    "parser.add_argument(\"--name\", type=str, help='the unique directory name for each experiment')\n",
    "parser.add_argument(\"--weights_epoch\", type=int, default=199, help='epoch of the weights to load')\n",
    "parser.add_argument(\"--manualSeed\", type=int, help=\"seed for training\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# unique dir for outputs, weights, and results\n",
    "if args.name is None:\n",
    "    unique_dir = f'{args.n_epochs}{args.batch_size}{args.lr}{args.image_size}'\n",
    "else:\n",
    "    unique_dir = args.name\n",
    "\n",
    "print(f'Experiment name: {unique_dir}')\n",
    "\n",
    "# create directories for results\n",
    "try:\n",
    "    os.makedirs(os.path.join(\"./results\", args.dataset, unique_dir, \"A\"))\n",
    "    os.makedirs(os.path.join(\"./results\", args.dataset, unique_dir, \"B\"))\n",
    "except OSError:\n",
    "    pass\n",
    "\n",
    "# directory for weights\n",
    "weights_dir = os.path.join(\"./weights\", args.dataset, unique_dir)\n",
    "\n",
    "# define transformations\n",
    "data_transform = transforms.Compose([\n",
    "                    transforms.Resize(int(args.image_size * 1.12), Image.BICUBIC),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
    "\n",
    "# create datasets\n",
    "dataset_A = datasets.ImageFolder(root=os.path.join(args.dataroot, args.dataset, \"test\", \"A\"), \n",
    "                                 transform=data_transform)\n",
    "dataset_B = datasets.ImageFolder(root=os.path.join(args.dataroot, args.dataset, \"test\", \"B\"), \n",
    "                                 transform=data_transform)\n",
    "\n",
    "# create dataloader (note: pin_memory=True makes transferring samples to GPU faster)\n",
    "dataloader_A = DataLoader(dataset_A, batch_size=args.batch_size, pin_memory=args.cuda)\n",
    "dataloader_B = DataLoader(dataset_B, batch_size=args.batch_size, pin_memory=args.cuda)\n",
    "\n",
    "# set device to cuda if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# create models\n",
    "g_AB = model.CycleGAN().to(device)\n",
    "g_BA = model.CycleGAN().to(device)\n",
    "\n",
    "# Load state dicts\n",
    "g_AB.load_state_dict(torch.load(os.path.join(weights_dir, f'g_AB_epoch_{args.weights_epoch}.pth')))\n",
    "g_BA.load_state_dict(torch.load(os.path.join(weights_dir, f'g_BA_epoch_{args.weights_epoch}.pth')))\n",
    "\n",
    "# Set models to eval mode\n",
    "g_AB.eval()\n",
    "g_BA.eval()\n",
    "\n",
    "# human to anime loop\n",
    "for i, (data, target) in enumerate(dataloader_A):\n",
    "    # get images\n",
    "    real_img_A = data.to(device)\n",
    "\n",
    "    # Generate output\n",
    "    fake_img_B = 0.5 * (g_AB(real_img_A).data + 1.0)\n",
    "\n",
    "    # Save image files\n",
    "    vutils.save_image(real_img_A.detach(), f\"./results/{args.dataset}/{unique_dir}/A/real_{i}.png\", normalize=True)\n",
    "    vutils.save_image(fake_img_B.detach(), f\"./results/{args.dataset}/{unique_dir}/A/fake_{i}.png\", normalize=True)\n",
    "print(f'{len(dataloader_A)} human to anime images generated')    \n",
    "\n",
    "# anime to human loop\n",
    "for i, (data, target) in enumerate(dataloader_B):\n",
    "    # get images\n",
    "    real_img_B = data.to(device)\n",
    "\n",
    "    # Generate output\n",
    "    fake_img_A = 0.5 * (g_BA(real_img_B).data + 1.0)\n",
    "\n",
    "    # Save image files\n",
    "    vutils.save_image(real_img_B.detach(), f\"./results/{args.dataset}/{unique_dir}/B/real_{i}.png\", normalize=True)\n",
    "    vutils.save_image(fake_img_A.detach(), f\"./results/{args.dataset}/{unique_dir}/B/fake_{i}.png\", normalize=True)\n",
    "print(f'{len(dataloader_B)} anime to human images generated')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results\\\\A'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "mydir = os.path.join(\"./results\", \"A\")\n",
    "str(mydir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./results\\\\A\\\\extra_dir'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(mydir, 'extra_dir')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
